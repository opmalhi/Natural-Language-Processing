{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. NLTK provides a plethora of algorithms to choose from for a particular problem which is boon for a researcher but a bane for a developer. Whereas, spaCy keeps the best algorithm for a problem in its toolkit and keep it updated as state of the art improves.\n",
        "\n",
        "2. NLTK supports various languages whereas spaCy have statistical models for 7 languages (English, German, Spanish, French, Portuguese, Italian, and Dutch). It also supports named entities for multi language.\n",
        "\n",
        "3. NLTK is a string processing library. It takes strings as input and returns strings or lists of strings as output. Whereas, spaCy uses object-oriented approach. When we parse a text, spaCy returns document object whose words and sentences are objects themselves.\n",
        "\n",
        "4. spaCy has support for word vectors whereas NLTK does not.\n",
        "\n",
        "5. As spaCy uses the latest and best algorithms, its performance is usually good as compared to NLTK. In word tokenization and POS-tagging spaCy performs better, but in sentence tokenization, NLTK outperforms spaCy. Its poor performance in sentence tokenization is a result of differing approaches: NLTK attempts to split the text into sentences. In contrast, spaCy constructs a syntactic tree for each sentence, a more robust method that yields much more information about the text.\n"
      ],
      "metadata": {
        "id": "L0dRwHqiPnh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SpaCy"
      ],
      "metadata": {
        "id": "6lldywqzU7SI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjNl3o51PSwv"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how we do \"Sentence Tokenization\" in SpaCy."
      ],
      "metadata": {
        "id": "z0-TEt09VhIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. The movie is awesome. It was a good thriller\")\n",
        "\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4m1sEa5U6p1",
        "outputId": "50c889ce-545f-4eec-c3c2-79a9f35a382c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple is looking at buying U.K. startup for $1 billion.\n",
            "The movie is awesome.\n",
            "It was a good thriller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how we do \"Word Tokenization\" in SpaCy."
      ],
      "metadata": {
        "id": "S6Jg0-FCVlbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaQ-c-MEVGMP",
        "outputId": "0a466523-8127-42c7-b232-37e884f549f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n",
            ".\n",
            "The\n",
            "movie\n",
            "is\n",
            "awesome\n",
            ".\n",
            "It\n",
            "was\n",
            "a\n",
            "good\n",
            "thriller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLTK"
      ],
      "metadata": {
        "id": "hXsPxqPfV-Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivr6WxdiVy8Z",
        "outputId": "8280e7ee-fd0e-4cea-be8b-fd68aa671e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(\"Apple is looking at buying U.K. startup for $1 billion. The movie is awesome. It was a good thriller and Dr. Strange was amazing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icLQqikQWAYJ",
        "outputId": "55b9122f-e729-45b7-ac82-69e34c026055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apple is looking at buying U.K. startup for $1 billion.',\n",
              " 'The movie is awesome.',\n",
              " 'It was a good thriller and Dr.',\n",
              " 'Strange was amazing']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see nltk doesn't separate sentences correctly because it is not provides us best algorithm we have to manually choose algo to make it powerful for our model."
      ],
      "metadata": {
        "id": "8j51xwl2XmAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Apple is looking at buying U.K. startup for $1 billion. The movie is awesome. It was a good thriller and Dr. Strange was amazing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUgStdboXGs0",
        "outputId": "10500bc1-4373-441e-9e8f-82e29eff9327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apple',\n",
              " 'is',\n",
              " 'looking',\n",
              " 'at',\n",
              " 'buying',\n",
              " 'U.K.',\n",
              " 'startup',\n",
              " 'for',\n",
              " '$',\n",
              " '1',\n",
              " 'billion',\n",
              " '.',\n",
              " 'The',\n",
              " 'movie',\n",
              " 'is',\n",
              " 'awesome',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'a',\n",
              " 'good',\n",
              " 'thriller',\n",
              " 'and',\n",
              " 'Dr',\n",
              " '.',\n",
              " 'Strange',\n",
              " 'was',\n",
              " 'amazing']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHAXdexZYrs0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}