{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition (NER)\n",
        "\n",
        "- we are going to use in built NER system using SpaCy library\n"
      ],
      "metadata": {
        "id": "Amy3pjCgydoZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUBQ3H-mx5hX",
        "outputId": "4a64ddc1-3cdc-493a-eab0-9a248db6ee31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a198hZZSyRI2",
        "outputId": "082113e6-1a2b-4a20-c3f9-b8dfb261f79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have a \"ner\" component in spacy that we are going to use"
      ],
      "metadata": {
        "id": "K8WGBrHTzNCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Microsoft is going to acquire tiktok for $50 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pFZ1fBQyXNS",
        "outputId": "5ecf41ca-6384-46f5-de51-62545a78e3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft | ORG | Companies, agencies, institutions, etc.\n",
            "$50 billion | MONEY | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can observe that this component is utilizing a pattern that prevented tiktok from being recognized as an organization in the document text. However, it will recognize Tiktok as an organization if we capitalize the letter \"t\" as Tiktok."
      ],
      "metadata": {
        "id": "fpvb5F760VET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Microsoft is going to acquire Tiktok for $50 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyiqQm2B16HY",
        "outputId": "3f3380f6-bfce-41e7-b241-f32611412ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft | ORG | Companies, agencies, institutions, etc.\n",
            "Tiktok | ORG | Companies, agencies, institutions, etc.\n",
            "$50 billion | MONEY | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6vxDpIzFzt8t",
        "outputId": "d8751483-348a-4341-8c28-3310c16fcd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla Inc\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is going to acquire twitter for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $45 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing all entites that praticular pre-trained model support"
      ],
      "metadata": {
        "id": "sHkOeitF20-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_labels['ner']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUKJ4CP30GFk",
        "outputId": "d1315f44-bd4c-41f7-f452-95b1cf0f27a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CARDINAL',\n",
              " 'DATE',\n",
              " 'EVENT',\n",
              " 'FAC',\n",
              " 'GPE',\n",
              " 'LANGUAGE',\n",
              " 'LAW',\n",
              " 'LOC',\n",
              " 'MONEY',\n",
              " 'NORP',\n",
              " 'ORDINAL',\n",
              " 'ORG',\n",
              " 'PERCENT',\n",
              " 'PERSON',\n",
              " 'PRODUCT',\n",
              " 'QUANTITY',\n",
              " 'TIME',\n",
              " 'WORK_OF_ART']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Michael Bloomberg founded Bloomberg in 1982\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V14wvZx53JlH",
        "outputId": "2903ad17-2159-4ef6-d0af-f50c735557ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Michael Bloomberg | PERSON | People, including fictional\n",
            "Bloomberg | PERSON | People, including fictional\n",
            "1982 | DATE | Absolute or relative dates or periods\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above cell it made a mistake in identifying Bloomberg the Company."
      ],
      "metadata": {
        "id": "dL1Vcnvw5RjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla is going to acquire Twitter for $45 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTYuBeST5O1x",
        "outputId": "401114d2-f8c3-4fa5-a88d-8e98589ad619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla | ORG | Companies, agencies, institutions, etc.\n",
            "Twitter | PRODUCT | Objects, vehicles, foods, etc. (not services)\n",
            "$45 billion | MONEY | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above cell it identified Twitter as a product. let's modify that in pre-trained model of SpaCy library."
      ],
      "metadata": {
        "id": "Pl6NGkPD6ON5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Custom Entity"
      ],
      "metadata": {
        "id": "TxBpalEc7Jbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amu6Reii6w_i",
        "outputId": "162ba00c-0254-45ee-fe10-70e9fcfd67ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tesla"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9fd7Zw26ILx",
        "outputId": "a09821bb-b136-4d73-97b7-6f3183241a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBNYZjak6wEK",
        "outputId": "d774eda1-0aa6-4121-9a75-ca5b24733b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tesla is going to acquire"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5rABIaB60v1",
        "outputId": "3464bef6-e3f1-4cb0-fa52-8bd39dcb04f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.span.Span"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To customize the entity we need to pass span not token."
      ],
      "metadata": {
        "id": "y4BTnGJB8ZPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Span\n",
        "\n",
        "s1 = Span(doc, 5, 6, label=\"ORG\")\n",
        "\n",
        "doc.set_ents([s1], default=\"unmodified\")"
      ],
      "metadata": {
        "id": "sYda4iiS64nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have more span then we just need to pass in the array in first parameter of set_ents as set_ents([s1, s2, s3], default=\"\")."
      ],
      "metadata": {
        "id": "zH4f5MTe80eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "  print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFQKsWrk8z0G",
        "outputId": "7377fa8a-b146-43b9-8316-718e9caa0832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla | ORG | Companies, agencies, institutions, etc.\n",
            "Twitter | ORG | Companies, agencies, institutions, etc.\n",
            "$45 billion | MONEY | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise"
      ],
      "metadata": {
        "id": "sOzsYIcx-eAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Excersie: 1**\n",
        "- Extract all the Geographical (cities, Countries, states) names from a given text"
      ],
      "metadata": {
        "id": "VIo3fwVi-g8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Kiran want to know the famous foods in each state of India. So, he opened Google and search for this question. Google showed that\n",
        "in Delhi it is Chaat, in Gujarat it is Dal Dhokli, in Tamilnadu it is Pongal, in Andhrapradesh it is Biryani, in Assam it is Papaya Khar,\n",
        "in Bihar it is Litti Chowkha and so on for all other states\"\"\"\n",
        "\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "oSE2xW5J9O_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "\n",
        "Geographical location Names: [India, Delhi, Gujarat, Tamilnadu, Andhrapradesh, Assam, Bihar]\n",
        "\n",
        "Count: 7"
      ],
      "metadata": {
        "id": "UrwXkUrg-q_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Location = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ == \"GPE\":\n",
        "    Location.append(ent)\n",
        "\n",
        "print(\"Geographical location Names: \", Location)\n",
        "print(\"Count: \", len(Location))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUoSfect-wnl",
        "outputId": "1163d1d9-d4b3-4316-f061-9e1b23627a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geographical location Names:  [India, Delhi, Gujarat, Tamilnadu, Pongal, Andhrapradesh, Assam, Bihar]\n",
            "Count:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this pre-trained model consider Pongal as country that's why output is 8 countries."
      ],
      "metadata": {
        "id": "n6Qzn3X6A_1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Excersie: 2**\n",
        "\n",
        "- Extract all the birth dates of cricketers in the given Text"
      ],
      "metadata": {
        "id": "VwBjNvN8-0nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Sachin Tendulkar was born on 24 April 1973, Virat Kholi was born on 5 November 1988, Dhoni was born on 7 July 1981\n",
        "and finally Ricky ponting was born on 19 December 1974.\"\"\"\n",
        "\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "_RZaPNZj-5ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output:**\n",
        "\n",
        "All Birth Dates: [24 April 1973, 5 November 1988, 7 July 1981, 19 December 1974]\n",
        "\n",
        "Count: 4"
      ],
      "metadata": {
        "id": "NFrRK6gu-9S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dob = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.label_ == \"DATE\":\n",
        "    dob.append(ent)\n",
        "\n",
        "print(\"All Birth Dates: \", dob)\n",
        "print(\"Count: \", len(dob))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TR1kcMx-7XN",
        "outputId": "463b0466-28e3-4b57-cc18-cdc945e945b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Birth Dates:  [24 April 1973, 5 November 1988, 7 July 1981, 19 December 1974]\n",
            "Count:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2BsnFMtARMq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}